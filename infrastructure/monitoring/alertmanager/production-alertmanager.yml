# Production Alertmanager Configuration for LabelMint
# ===================================================

global:
  # SMTP Configuration
  smtp_smarthost: '${SMTP_HOST:smtp.gmail.com:587}'
  smtp_from: '${SMTP_FROM:alerts@labelmint.it}'
  smtp_auth_username: '${SMTP_USERNAME:alerts@labelmint.it}'
  smtp_auth_password: '${SMTP_PASSWORD}'
  smtp_require_tls: true

  # Global labels
  resolve_timeout: 5m

  # Slack API configuration
  slack_api_url: '${SLACK_API_URL}'

  # PagerDuty configuration
  pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'

# Templates for alert notifications
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Inhibition rules to prevent alert spam
inhibit_rules:
  # Inhibit non-critical alerts when critical alerts are firing for the same service
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'service', 'instance']

  # Inhibit all alerts if the entire service is down
  - source_match:
      alertname: 'ServiceDown'
    target_match_re:
      alertname: '^(?!ServiceDown).*'
    equal: ['service', 'instance']

  # Inhibit node-specific alerts if the entire node is down
  - source_match:
      alertname: 'InstanceDown'
    target_match_re:
      alertname: '^(?!InstanceDown).*'
    equal: ['instance']

# Routing configuration with intelligent routing
route:
  # Default routing configuration
  group_by: ['alertname', 'cluster', 'service', 'severity']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 12h
  receiver: 'default-email'

  # Route rules based on severity and service
  routes:
    # Critical alerts - immediate escalation
    - match:
        severity: critical
      group_wait: 10s
      group_interval: 1m
      repeat_interval: 5m
      receiver: 'critical-alerts'
      routes:
        # Security critical alerts - immediate security team notification
        - match:
            team: security
          receiver: 'security-critical'
        # Finance critical alerts - finance team notification
        - match:
            team: finance
          receiver: 'finance-critical'
        # Database critical alerts - on-call DBA notification
        - match:
            service: database
          receiver: 'database-critical'

    # Warning alerts - standard escalation
    - match:
        severity: warning
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 2h
      receiver: 'warning-alerts'
      routes:
        # Security warnings - security team
        - match:
            team: security
          receiver: 'security-warning'
        # Business warnings - product team
        - match:
            team: product
          receiver: 'business-warning'

    # Info alerts - email only
    - match:
        severity: info
      group_wait: 5m
      group_interval: 30m
      repeat_interval: 24h
      receiver: 'info-alerts'

    # Business hours routing for non-critical alerts
    - match:
        severity: warning
      active_time_intervals:
        - business-hours
      receiver: 'business-hours-warning'

    # Weekend routing - escalate to on-call
    - match:
        severity: warning
      active_time_intervals:
        - weekends
      receiver: 'weekend-oncall'

# Notification receivers
receivers:
  # Default email receiver
  - name: 'default-email'
    email_configs:
      - to: '${DEFAULT_EMAIL:devops@labelmint.it}'
        subject: '[{{ .Status | toUpper }}] LabelMint Alert: {{ .GroupLabels.alertname }}'
        body: |
          üìä **LabelMint Alert Dashboard**

          {{ range .Alerts }}
          üö® **Alert**: {{ .Annotations.summary }}
          üìù **Description**: {{ .Annotations.description }}
          üîó **Runbook**: {{ .Annotations.runbook_url }}

          **Labels**:
          {{ range .Labels.SortedPairs }}‚Ä¢ {{ .Name }}: {{ .Value }}
          {{ end }}

          **Started**: {{ .StartsAt.Format "2006-01-02 15:04:05 UTC" }}
          {{ if .EndsAt }}**Resolved**: {{ .EndsAt.Format "2006-01-02 15:04:05 UTC" }}{{ end }}

          ---
          {{ end }}

          **Cluster**: {{ .GroupLabels.cluster }}
          **Service**: {{ .GroupLabels.service }}
          **Severity**: {{ .GroupLabels.severity }}

  # Critical alerts - multi-channel escalation
  - name: 'critical-alerts'
    email_configs:
      - to: '${CRITICAL_EMAIL:oncall@labelmint.it,devops@labelmint.it}'
        subject: '[CRITICAL] üö® LabelMint Production Alert'
        body: |
          üö® **CRITICAL ALERT - IMMEDIATE ACTION REQUIRED** üö®

          {{ range .Alerts }}
          **{{ .Annotations.summary }}**
          {{ .Annotations.description }}

          üîó **Runbook**: {{ .Annotations.runbook_url }}
          ‚è∞ **Started**: {{ .StartsAt.Format "2006-01-02 15:04:05 UTC" }}
          üè∑Ô∏è **Instance**: {{ .Labels.instance }}
          üè∑Ô∏è **Service**: {{ .Labels.service }}
          {{ end }}

          üì± **PagerDuty**: This alert has been escalated to PagerDuty
          üí¨ **Slack**: Posted to #alerts-critical channel

    slack_configs:
      - api_url: '${SLACK_CRITICAL_WEBHOOK}'
        channel: '#alerts-critical'
        title: 'üö® CRITICAL PRODUCTION ALERT'
        text: |
          {{ range .Alerts }}
          *{{ .Annotations.summary }}*
          {{ .Annotations.description }}
          üîó Runbook: {{ .Annotations.runbook_url }}
          {{ end }}
        actions:
          - type: button
            text: 'View in Grafana'
            url: 'https://grafana.labelmint.it'
          - type: button
            text: 'Acknowledge'
            url: 'https://alertmanager.labelmint.it'

    pagerduty_configs:
      - service_key: '${PAGERDUTY_SERVICE_KEY}'
        description: '{{ .GroupLabels.alertname }}: {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
        severity: 'critical'
        details:
          cluster: '{{ .GroupLabels.cluster }}'
          service: '{{ .GroupLabels.service }}'
          runbook_url: '{{ range .Alerts }}{{ .Annotations.runbook_url }}{{ end }}'
          firing: '{{ .Alerts.Firing | len }}'
          resolved: '{{ .Alerts.Resolved | len }}'

    webhook_configs:
      - url: '${TEAMS_WEBHOOK_URL}'
        send_resolved: true
        title: 'CRITICAL: LabelMint Alert'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'

  # Security critical alerts - security team only
  - name: 'security-critical'
    email_configs:
      - to: '${SECURITY_EMAIL:security@labelmint.it,csirt@labelmint.it}'
        subject: '[SECURITY-CRITICAL] üõ°Ô∏è LabelMint Security Alert'
        body: |
          üõ°Ô∏è **SECURITY CRITICAL ALERT** üõ°Ô∏è

          {{ range .Alerts }}
          **Attack Type**: {{ .Labels.attack_type }}
          **Summary**: {{ .Annotations.summary }}
          **Description**: {{ .Annotations.description }}

          üîó **Runbook**: {{ .Annotations.runbook_url }}
          üïê **Started**: {{ .StartsAt.Format "2006-01-02 15:04:05 UTC" }}
          {{ end }}

          **Immediate Actions Required**:
          1. Review security dashboard
          2. Check for active threats
          3. Document incident
          4. Escalate if needed

    slack_configs:
      - api_url: '${SLACK_SECURITY_WEBHOOK}'
        channel: '#security-alerts'
        title: 'üõ°Ô∏è SECURITY CRITICAL ALERT'
        text: |
          {{ range .Alerts }}
          *{{ .Annotations.summary }}*
          Attack Type: {{ .Labels.attack_type }}
          {{ .Annotations.description }}
          {{ end }}

  # Finance critical alerts
  - name: 'finance-critical'
    email_configs:
      - to: '${FINANCE_EMAIL:finance@labelmint.it,cfo@labelmint.it}'
        subject: '[FINANCE-CRITICAL] üí∞ LabelMint Financial Alert'
        body: |
          üí∞ **FINANCIAL CRITICAL ALERT** üí∞

          {{ range .Alerts }}
          **Summary**: {{ .Annotations.summary }}
          **Description**: {{ .Annotations.description }}

          üîó **Runbook**: {{ .Annotations.runbook_url }}
          {{ end }}

          **Financial Impact**: Review payment systems immediately

    slack_configs:
      - api_url: '${SLACK_FINANCE_WEBHOOK}'
        channel: '#finance-alerts'
        title: 'üí∞ FINANCIAL CRITICAL ALERT'
        text: |
          {{ range .Alerts }}
          *{{ .Annotations.summary }}*
          {{ .Annotations.description }}
          {{ end }}

  # Database critical alerts
  - name: 'database-critical'
    email_configs:
      - to: '${DBA_EMAIL:dba@labelmint.it,devops@labelmint.it}'
        subject: '[DB-CRITICAL] üóÑÔ∏è LabelMint Database Alert'
        body: |
          üóÑÔ∏è **DATABASE CRITICAL ALERT** üóÑÔ∏è

          {{ range .Alerts }}
          **Summary**: {{ .Annotations.summary }}
          **Description**: {{ .Annotations.description }}

          üîó **Runbook**: {{ .Annotations.runbook_url }}
          {{ end }}

          **Database Performance**: Immediate investigation required

    pagerduty_configs:
      - service_key: '${PAGERDUTY_DBA_SERVICE_KEY}'
        description: 'Database Critical: {{ .GroupLabels.alertname }}'
        severity: 'critical'

  # Warning alerts
  - name: 'warning-alerts'
    email_configs:
      - to: '${WARNING_EMAIL:devops@labelmint.it}'
        subject: '[WARNING] ‚ö†Ô∏è LabelMint Alert'
        body: |
          ‚ö†Ô∏è **WARNING ALERT** ‚ö†Ô∏è

          {{ range .Alerts }}
          **{{ .Annotations.summary }}**
          {{ .Annotations.description }}

          üîó **Runbook**: {{ .Annotations.runbook_url }}
          {{ end }}

    slack_configs:
      - api_url: '${SLACK_WARNING_WEBHOOK}'
        channel: '#alerts'
        title: '‚ö†Ô∏è Warning Alert'
        color: 'warning'
        text: |
          {{ range .Alerts }}
          *{{ .Annotations.summary }}*
          {{ .Annotations.description }}
          {{ end }}

  # Info alerts
  - name: 'info-alerts'
    email_configs:
      - to: '${INFO_EMAIL:devops@labelmint.it}'
        subject: '[INFO] ‚ÑπÔ∏è LabelMint Alert'
        body: |
          ‚ÑπÔ∏è **INFORMATION ALERT** ‚ÑπÔ∏è

          {{ range .Alerts }}
          **{{ .Annotations.summary }}**
          {{ .Annotations.description }}
          {{ end }}

  # Business hours warning routing
  - name: 'business-hours-warning'
    email_configs:
      - to: '${BUSINESS_HOURS_EMAIL:product@labelmint.it'
        subject: '[BUSINESS-HOURS] ‚ö†Ô∏è LabelMint Alert'

  # Weekend on-call routing
  - name: 'weekend-oncall'
    email_configs:
      - to: '${WEEKEND_ONCALL_EMAIL:oncall@labelmint.it}'
        subject: '[WEEKEND-ONCALL] ‚ö†Ô∏è LabelMint Alert'
    pagerduty_configs:
      - service_key: '${PAGERDUTY_WEEKEND_SERVICE_KEY}'
        description: 'Weekend Alert: {{ .GroupLabels.alertname }}'

# Time intervals for scheduling
time_intervals:
  - name: 'business-hours'
    time_intervals:
      - times:
          - start_time: '09:00'
            end_time: '17:00'
        weekdays: ['monday:friday']
        location: 'UTC'

  - name: 'weekends'
    time_intervals:
      - weekdays: ['saturday:sunday']
        location: 'UTC'

  - name: 'after-hours'
    time_intervals:
      - times:
          - start_time: '17:01'
            end_time: '23:59'
          - start_time: '00:00'
            end_time: '08:59'
        weekdays: ['monday:friday']
        location: 'UTC'

# Silence configuration for maintenance windows
silences:
  # No default silences - all must be created explicitly