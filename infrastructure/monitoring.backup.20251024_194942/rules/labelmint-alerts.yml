# Unified LabelMint Alert Rules
# Comprehensive monitoring alerts for all LabelMint services

groups:
  # Infrastructure Alerts
  - name: labelmint-infrastructure
    rules:
      - alert: NodeDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
          service: infrastructure
          component: node
        annotations:
          summary: "Node {{ $labels.instance }} is down"
          description: "Node {{ $labels.instance }} has been down for more than 1 minute."
          runbook_url: "https://runbooks.labelmint.com/node-down"

      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
          service: infrastructure
          component: node
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is above 80% for more than 5 minutes on {{ $labels.instance }}. Current value: {{ $value }}%"

      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 5m
        labels:
          severity: warning
          service: infrastructure
          component: node
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is above 85% for more than 5 minutes on {{ $labels.instance }}. Current value: {{ $value }}%"

      - alert: DiskSpaceLow
        expr: (1 - (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"})) * 100 > 90
        for: 2m
        labels:
          severity: critical
          service: infrastructure
          component: node
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Disk space is below 10% on {{ $labels.instance }}. Current usage: {{ $value }}%"

  # Database Alerts
  - name: labelmint-database
    rules:
      - alert: PostgresDown
        expr: up{job="labelmint-postgres"} == 0
        for: 30s
        labels:
          severity: critical
          service: database
          component: postgres
        annotations:
          summary: "PostgreSQL is down"
          description: "PostgreSQL has been down for more than 30 seconds."

      - alert: PostgresTooManyConnections
        expr: pg_stat_database_numbackends / pg_settings_max_connections * 100 > 80
        for: 5m
        labels:
          severity: warning
          service: database
          component: postgres
        annotations:
          summary: "PostgreSQL has too many connections"
          description: "PostgreSQL has more than 80% connections used. Current: {{ $value }}%"

      - alert: PostgresSlowQueries
        expr: rate(pg_stat_statements_mean_time_seconds[5m]) > 1
        for: 5m
        labels:
          severity: warning
          service: database
          component: postgres
        annotations:
          summary: "PostgreSQL slow queries detected"
          description: "PostgreSQL average query time is above 1 second. Current: {{ $value }}s"

      - alert: RedisDown
        expr: up{job="labelmint-redis"} == 0
        for: 30s
        labels:
          severity: critical
          service: database
          component: redis
        annotations:
          summary: "Redis is down"
          description: "Redis has been down for more than 30 seconds."

      - alert: RedisHighMemoryUsage
        expr: redis_memory_used_bytes / redis_memory_max_bytes * 100 > 90
        for: 5m
        labels:
          severity: warning
          service: database
          component: redis
        annotations:
          summary: "Redis high memory usage"
          description: "Redis memory usage is above 90%. Current: {{ $value }}%"

  # Application Alerts
  - name: labelmint-application
    rules:
      - alert: LabelingBackendDown
        expr: up{job="labelmint-labeling-backend"} == 0
        for: 30s
        labels:
          severity: critical
          service: application
          component: labeling-backend
        annotations:
          summary: "Labeling backend is down"
          description: "Labeling backend has been down for more than 30 seconds."

      - alert: PaymentBackendDown
        expr: up{job="labelmint-payment-backend"} == 0
        for: 30s
        labels:
          severity: critical
          service: application
          component: payment-backend
        annotations:
          summary: "Payment backend is down"
          description: "Payment backend has been down for more than 30 seconds."

      - alert: WebApplicationDown
        expr: up{job="labelmint-web"} == 0
        for: 30s
        labels:
          severity: critical
          service: application
          component: web
        annotations:
          summary: "Web application is down"
          description: "Web application has been down for more than 30 seconds."

      - alert: APIGatewayDown
        expr: up{job="labelmint-api-gateway"} == 0
        for: 30s
        labels:
          severity: critical
          service: application
          component: api-gateway
        annotations:
          summary: "API Gateway is down"
          description: "API Gateway has been down for more than 30 seconds."

      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) * 100 > 5
        for: 3m
        labels:
          severity: warning
          service: application
        annotations:
          summary: "High error rate detected"
          description: "Error rate is above 5% for more than 3 minutes. Current: {{ $value }}%"

      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
          service: application
        annotations:
          summary: "High latency detected"
          description: "95th percentile latency is above 1 second for more than 5 minutes. Current: {{ $value }}s"

      - alert: BotServiceDown
        expr: up{job=~"labelmint-.*-bot"} == 0
        for: 1m
        labels:
          severity: warning
          service: application
          component: bots
        annotations:
          summary: "Bot service is down"
          description: "{{ $labels.job }} has been down for more than 1 minute."

  # Storage Alerts
  - name: labelmint-storage
    rules:
      - alert: MinIODown
        expr: up{job="labelmint-minio"} == 0
        for: 30s
        labels:
          severity: critical
          service: storage
          component: minio
        annotations:
          summary: "MinIO is down"
          description: "MinIO object storage has been down for more than 30 seconds."

      - alert: MinIODiskSpaceLow
        expr: minio_disk_free_bytes / minio_disk_total_bytes * 100 < 10
        for: 2m
        labels:
          severity: critical
          service: storage
          component: minio
        annotations:
          summary: "MinIO low disk space"
          description: "MinIO has less than 10% free disk space. Current: {{ $value }}%"

  # Monitoring System Alerts
  - name: labelmint-monitoring
    rules:
      - alert: PrometheusDown
        expr: up{job="prometheus"} == 0
        for: 1m
        labels:
          severity: critical
          service: monitoring
          component: prometheus
        annotations:
          summary: "Prometheus is down"
          description: "Prometheus has been down for more than 1 minute."

      - alert: PrometheusTooManyScrapesFailing
        expr: rate(prometheus_scrape_scrapes_failed_total[5m]) / rate(prometheus_scrape_scrapes_total[5m]) * 100 > 10
        for: 5m
        labels:
          severity: warning
          service: monitoring
          component: prometheus
        annotations:
          summary: "Too many Prometheus scrapes failing"
          description: "More than 10% of Prometheus scrapes are failing. Current: {{ $value }}%"

      - alert: GrafanaDown
        expr: up{job="labelmint-grafana"} == 0
        for: 1m
        labels:
          severity: warning
          service: monitoring
          component: grafana
        annotations:
          summary: "Grafana is down"
          description: "Grafana has been down for more than 1 minute."

      - alert: LokiDown
        expr: up{job="labelmint-loki"} == 0
        for: 1m
        labels:
          severity: warning
          service: monitoring
          component: loki
        annotations:
          summary: "Loki is down"
          description: "Loki has been down for more than 1 minute."

      - alert: TempoDown
        expr: up{job="labelmint-tempo"} == 0
        for: 1m
        labels:
          severity: warning
          service: monitoring
          component: tempo
        annotations:
          summary: "Tempo is down"
          description: "Tempo has been down for more than 1 minute."

  # Security Alerts
  - name: labelmint-security
    rules:
      - alert: UnauthorizedAccess
        expr: rate(http_requests_total{status="401"}[5m]) > 10
        for: 2m
        labels:
          severity: warning
          service: security
          type: authentication
        annotations:
          summary: "High rate of unauthorized access attempts"
          description: "More than 10 unauthorized access attempts per minute detected. Current: {{ $value }}/min"

      - alert: SuspiciousActivity
        expr: rate(http_requests_total{status="403"}[5m]) > 5
        for: 2m
        labels:
          severity: warning
          service: security
          type: authorization
        annotations:
          summary: "High rate of forbidden requests"
          description: "More than 5 forbidden requests per minute detected. Current: {{ $value }}/min"

  # Business Metrics Alerts
  - name: labelmint-business
    rules:
      - alert: LowOrderVolume
        expr: rate(labelmint_orders_total[1h]) < 1
        for: 10m
        labels:
          severity: info
          service: business
          metric: orders
        annotations:
          summary: "Low order volume detected"
          description: "Order rate is below 1 per hour for the last 10 minutes. Current: {{ $value }}/hour"

      - alert: HighErrorRateBusiness
        expr: rate(labelmint_errors_total[5m]) / rate(labelmint_requests_total[5m]) * 100 > 2
        for: 3m
        labels:
          severity: warning
          service: business
          metric: errors
        annotations:
          summary: "High business error rate"
          description: "Business error rate is above 2% for more than 3 minutes. Current: {{ $value }}%"